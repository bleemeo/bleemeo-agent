#
#  Copyright 2015-2016 Bleemeo
#
#  bleemeo.com an infrastructure monitoring solution in the Cloud
#
#   Licensed under the Apache License, Version 2.0 (the "License");
#   you may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.
#
# pylint: disable=too-many-lines

import distutils.version  # pylint: disable=import-error,no-name-in-module
import logging
import os
import re
import shlex
import subprocess
import time

import psutil
import requests
from six.moves import urllib_parse

import bleemeo_agent.type
import bleemeo_agent.util


BASE_TELEGRAF_CONFIG = """# Configuration generated by Bleemeo-agent.
# do NOT modify, it will be overwrite on next agent start.
[agent]
  interval = "%(interval)ss"
"""

STATSD_TELEGRAF_CONFIG = """
# Statsd Server
# To disable Statsd server, add:
#     telegraf:
#         statsd:
#             enabled: False
# in /etc/bleemeo/agent.conf.d/99-local.conf
[[inputs.statsd]]
  service_address = "%(address)s:%(port)s"
  delete_gauges = false
  delete_counters = false
  delete_timings = true
  percentiles = [90]
  metric_separator = "_"
  allowed_pending_messages = 10000
  percentile_limit = 1000
"""

APACHE_TELEGRAF_CONFIG = """
[[inputs.apache]]
  urls = ["%(status_url)s"]
"""

# Additional configuration if Telegraf >= 1.2.0
APACHE_TELEGRAF_CONFIG_1_2 = """
  insecure_skip_verify = true
"""


DOCKER_TELEGRAF_CONFIG = """
[[inputs.docker]]
    perdevice = false
    total = true
"""

ELASTICSEARCH_TELEGRAF_CONFIG = """
[[inputs.elasticsearch]]
  servers = ["http://%(address)s:%(port)s"]
  local = true
  cluster_health = false
"""

HAPROXY_TELEGRAF_CONFIG = """
[[inputs.haproxy]]
  servers = ["%(stats_url)s"]
"""

MEMCACHED_TELEGRAF_CONFIG = """
[[inputs.memcached]]
  servers = ["%(address)s:%(port)s"]
"""

MONGODB_TELEGRAF_CONFIG = """
[[inputs.mongodb]]
  servers = ["%(address)s:%(port)s"]
"""

MYSQL_TELEGRAF_CONFIG = """
[[inputs.mysql]]
  servers = ["%(username)s:%(password)s@tcp(%(address)s:%(port)s)/"]
"""

# Additional configuration if Telegraf >= 1.3.0
MYSQL_TELEGRAF_CONFIG_1_3 = """
  gather_innodb_metrics = true
"""

NGINX_TELEGRAF_CONFIG = """
[[inputs.nginx]]
  urls = ["http://%(address)s:%(port)s/nginx_status"]
"""

# Additional configuration if Telegraf >= 1.4.0
NGINX_TELEGRAF_CONFIG_1_4 = """
  insecure_skip_verify = true
"""

PHPFPM_TELEGRAF_CONFIG = """
[[inputs.phpfpm]]
    urls = ["%(stats_url)s"]
    %(tags)s
"""  # noqa

POSTGRESQL_TELEGRAF_CONFIG = """
[[inputs.postgresql]]
    address = "host=%(address)s port=%(port)s user=%(username)s password=%(password)s dbname=postgres sslmode=disable"
"""  # noqa

PROMETHEUS_TELEGRAF_CONFIG = """
[[inputs.prometheus]]
  urls = ["%(url)s"]
  name_prefix = "prometheus_%(prefix)s_"
"""

RABBITMQ_TELEGRAF_CONFIG = """
[[inputs.rabbitmq]]
  url = "http://%(address)s:%(mgmt_port)s"
  username = "%(username)s"
  password = "%(password)s"
"""

REDIS_TELEGRAF_CONFIG = """
[[inputs.redis]]
  servers = ["tcp://%(address)s:%(port)s"]
"""

ZOOKEEPER_CONFIG = """
[[inputs.zookeeper]]
  servers = ["%(address)s:%(port)s"]
"""


class ComputationFail(Exception):
    """ Exceptions raised when computed metrics failed to be computed and
        should not be retried
    """


class MissingMetric(Exception):
    """ Exceptions raised when a metric needed for a computed metrics is
        not (yet) present. The computed metrics should be retried later.
    """


def compare_version(current_version, wanted_version):
    """ Return True if current_version is greater or equal to wanted_version
    """
    # pylint: disable=no-member
    current_version = distutils.version.LooseVersion(current_version)
    wanted_version = distutils.version.LooseVersion(wanted_version)
    return current_version >= wanted_version


def telegraf_replace(value):
    """ telegraf replace some char before sending to graphite.

        This function do the same transformation
    """
    return (
        value
        .replace('/', '-')
        .replace('@', '-')
        .replace('*', '-')
        .replace(' ', '_')
        .replace('..', '.')
        .replace('\\', '')
        .replace(')', '_')
        .replace('(', '_')
        .replace('.', '_')
    )


def update_discovery(core):
    updated = False
    try:
        updated = _write_config(core)
    except Exception:  # pylint: disable=broad-except
        logging.warning(
            'Failed to write telegraf configuration. '
            'Continuing with current configuration')
        logging.debug('exception is:', exc_info=True)
    if updated:
        try:
            _restart_telegraf(core)
        except Exception:  # pylint: disable=broad-except
            logging.warning(
                'Failed to restart telegraf after configuration update. '
                'Continuing with current configuration')
            logging.debug('exception is:', exc_info=True)


class Telegraf:

    def __init__(self, graphite_client):
        self.core = graphite_client.core
        self.graphite_client = graphite_client
        self.graphite_server = graphite_client.server

        # used to compute derivated values
        self._raw_value = {}

        self.computed_metrics_pending = set()

        self.last_timestamp = 0
        self.last_depecated_telgraf_warning = 0

        self.core.add_scheduled_job(
            self._purge_metrics,
            seconds=5 * 60,
        )

    def _purge_metrics(self):
        """ Remove old metrics from self._raw_value
        """
        now = time.time()
        cutoff = now - 60 * 6

        # XXX: concurrent access with emit_metric
        self._raw_value = {
            key: (timestamp, value)
            for key, (timestamp, value) in self._raw_value.items()
            if timestamp >= cutoff
        }

    def get_derivate(self, name, item, timestamp, value):
        """ Return derivate of a COUNTER (e.g. something that only goes upward)
        """
        (old_timestamp, old_value) = self._raw_value.get(
            (name, item), (None, None)
        )
        self._raw_value[(name, item)] = (timestamp, value)
        if old_timestamp is None:
            return None

        delta = value - old_value
        delta_time = timestamp - old_timestamp

        if delta_time == 0:
            return None

        if delta < 0:
            return None

        return delta / delta_time

    def _get_service_instance(self, service, address, port):
        for (key, service_info) in self.core.services.items():
            (service_name, instance) = key
            if (service_name == service
                    and service_info.get('address') == address
                    and service_info.get('port') == port):
                return instance
            # RabbitMQ use mgmt port
            if (service_name == service
                    and service_name == 'rabbitmq'
                    and service_info.get('address') == address
                    and service_info.get('mgmt_port', 15672) == port):
                return instance

        raise KeyError('service not found')

    def _get_haproxy_instance(self, hostport):
        if ':' in hostport:
            host, port = hostport.split(':')
            port = int(port)
        else:
            host = hostport
            port = None

        for (key, service_info) in self.core.services.items():
            (service_name, instance) = key
            if service_name != 'haproxy':
                continue
            if 'stats_url' in service_info:
                tmp = urllib_parse.urlparse(service_info['stats_url'])
                if host == tmp.hostname and port == tmp.port:
                    return instance

        raise KeyError('service not found')

    def _get_elasticsearch_instance(self, node_id):
        for (key, service_info) in self.core.services.items():
            (service_name, instance) = key
            if service_name != 'elasticsearch':
                continue
            if not service_info.get('active', True):
                continue
            if service_info.get('address') is None:
                continue
            if service_info.get('port') is None:
                continue
            if 'es_node_id' not in service_info:
                try:
                    response = requests.get(
                        'http://%(address)s:%(port)s/_nodes/_local/'
                        % service_info,
                        headers={'User-Agent': self.core.http_user_agent},
                        timeout=10.0,
                    )
                    data = response.json()
                    this_node_id = list(data['nodes'].keys())[0]
                except (requests.RequestException, ValueError):
                    logging.debug(
                        'Error while fetching es_node_is', exc_info=True
                    )
                    continue

                service_info['es_node_id'] = this_node_id

            if service_info.get('es_node_id') == node_id:
                return instance

        raise KeyError('service not found')

    def get_prometheus_exporter_name(self, metric_name, part):
        """ Return the config of the Prometheus exporter
        """
        prometheus_configs = self.core.config['metric.prometheus']
        for name, config in prometheus_configs.items():
            url_mangled = telegraf_replace(config['url'])
            if (metric_name.startswith('%s_' % name)
                    and url_mangled in part):
                return name
        raise KeyError('prometheus config not found')

    def docker_container_tags(self, part, extra_properties=None):
        # pylint: disable=too-many-locals
        """ Return a mapping of metrics tag from Telegraf

            For docker container, Telegraf mix a fixed list of properties
            with user tags. This list is a list of key-value but when wrote on
            graphite it result in a list of value separated by "."

            For example:

            prefix=telegraf,host=xenial,a_custom_label=my_value,
                container_image=redis,container_name=my_redis,
                container_status=running,container_version=unknown,
                engine_host=xenial

            Result in:

            telegraf.xenial.my_value.redis.my_redis.running.unkonwn.xenial

            This method transform the graphite line in a mapping.
        """
        # This method works by:
        # * Counting the number of element in the graphite line
        # * Using Docker inspect, removing user-label
        # * This allow to find the Telegraf version (since we known the number
        #   of properties of any given version of Telegraf)
        # * From there we have the name of properties & user labels, we can
        #   revert the line.

        if extra_properties is None:
            extra_properties = []

        for name, inspect in self.core.docker_containers_by_name.items():
            labels = inspect.get('Config', {}).get('Labels', {})
            if labels is None:
                labels = {}

            user_keys = [
                key for (key, value) in labels.items()
                if value != ''
            ]

            # part always ends with 2 element which are the plugin name and
            # the measurement name. Ignore both of them.
            properties_count = len(part) - len(user_keys) - 2
            base_properties_count = properties_count - len(extra_properties)

            base_properties = [
                # Added in Telegraf <1.1.0
                "prefix",
                "host",
                "container_image",
                "container_name",
                "container_version",
                # Added in Telegraf 1.1.0
                "engine_host",
                # Added in Telegraf 1.7.0
                "server_version",
                # Added in Telegraf 1.8.0
                "container_status",
            ]

            if base_properties_count < 5:
                continue
            if base_properties_count > len(base_properties):
                continue

            properties = (
                base_properties[:base_properties_count] + extra_properties
            )

            label_keys_before = [
                key for (key, value) in labels.items()
                if key < "container_name" and value != ''
            ]
            position = 3 + len(label_keys_before)

            # Docker only allow "_", "." and "-" as special char in
            # container_name. Of those, only "." is replaced by "_"
            tmp = name.replace('.', '_')

            if len(part) <= position or part[position] != tmp:
                continue

            result = {}
            # We don't care about host or prefix metrics
            properties.remove("host")
            properties.remove("prefix")
            all_keys = properties + user_keys
            all_keys.sort()
            for (index, key) in enumerate(all_keys):
                result[key] = part[index + 2]  # +2 due to host and prefix
                if key == 'container_name':
                    # use de-mangled name
                    result[key] = name
            return result

        return None

    def _telegraf_compatibility(self, name):
        # pylint: disable=too-many-branches
        # pylint: disable=too-many-statements
        """ Parse old telegraf format without graphite_tag_support
        """
        if self.last_depecated_telgraf_warning < time.time() - 900:
            self.last_depecated_telgraf_warning = time.time()
            installation_format = self.core.last_facts.get(
                'installation_format', ''
            )
            if 'Package' in installation_format:
                logging.warning(
                    'Telegraf configuration is using depreacted option.'
                    ' Please upgrade package "telegraf" '
                    'and "bleemeo-agent-telegraf".'
                )
            else:
                logging.warning(
                    'Telegraf configuration is using depreacted option.'
                    ' Please upgrade Telegraf and its configuration.'
                )
            logging.warning(
                'See https://docs.bleemeo.com/agent/upgrade-agent/'
            )
        # name looks like
        # telegraf.HOSTNAME.(ITEM_INFO)*.PLUGIN.METRIC
        # example:
        # telegraf.xps-pierref.ext4./home.disk.total
        # telegraf.xps-pierref.mem.used
        # telegraf.xps-pierref.cpu-total.cpu.usage_steal
        part = name.split('.')
        part_dict = {
            'telegraf_plugin': part[-2],
            'metric_name': part[-1],
        }

        if part[-2] == 'cpu':
            part_dict['cpu'] = part[-3]
        elif part[-2] == 'disk':
            part_dict['fstype'] = part[3]
            part_dict['path'] = part[-3]
        elif part[-2] == 'diskio':
            part_dict['_name'] = part[2]
        elif part[-2] == 'net':
            part_dict['interface'] = part[-3]
        elif part[-2] == 'apache':
            part_dict['server'] = part[-3]
            part_dict['port'] = part[-4]
        elif part[-2] == 'haproxy':
            part_dict['proxy'] = part[2]
            part_dict['server'] = part[3]
            part_dict['sv'] = part[4]
        elif part[-2] == 'memcached':
            part_dict['server'] = part[-3]
        elif part[-2] in ('mysql', 'mysql_innodb'):
            part_dict['server'] = part[-3]
        elif part[-2] == 'nginx':
            part_dict['server'] = part[-3]
            part_dict['port'] = part[-4]
        elif part[-2] == 'postgresql':
            part_dict['db'] = part[2]
            part_dict['server'] = part[3]
        elif part[-2] == 'redis':
            # Prior to Telegraf 0.13.1, output was
            # telegraf.$HOSTNAME.$PORT.$SERVER.redis.$METRIC
            # Telegraf 0.13.1+, output is
            # telegraf.$HOSTNAME.$PORT.$ROLE.$SERVER.redis.$METRIC

            # Also, for both a $DATABASE may exists just after $HOSTNAME
            # E.g for 0.13.1:
            # telegraf.$HOSTNAME.$DATABASE.$PORT.$ROLE.$SERVER.redis.$METRIC
            #
            # $PORT is part[-4] or part[-5]
            # $SERVER is always part[-3]
            part_dict['server'] = part[-3]
            if part[-4] in ('master', 'slave'):
                part_dict['port'] = part[-5]
            else:
                part_dict['port'] = part[-4]
        elif part[-2] == 'zookeeper':
            part_dict['server'] = part[3]
            part_dict['port'] = part[2]
        elif part[-2] == 'mongodb':
            part_dict['hostname'] = part[-3]
        elif part[-2].startswith('elasticsearch_'):
            part_dict['node_id'] = part[-4]
        elif part[-2] == 'rabbitmq_overview':
            part_dict['url'] = part[-3]
        elif part[-2] == 'docker_container_cpu':
            container_tags = self.docker_container_tags(part, ["cpu"])
            if container_tags is None:
                return {}
            part_dict['container_name'] = container_tags['container_name']
            if 'cpu' in container_tags:
                part_dict['cpu'] = container_tags['cpu']
        elif part[-2] == 'docker_container_mem':
            container_tags = self.docker_container_tags(part, [])
            if container_tags is None:
                return {}
            part_dict['container_name'] = container_tags['container_name']
        elif part[-2] == 'docker_container_net':
            container_tags = self.docker_container_tags(part, ["network"])
            if container_tags is None:
                return {}
            part_dict['container_name'] = container_tags['container_name']
            if 'network' in container_tags:
                part_dict['network'] = container_tags['network']
        elif part[-2] == 'docker_container_blkio':
            container_tags = self.docker_container_tags(part, ["device"])
            if container_tags is None:
                return {}
            part_dict['container_name'] = container_tags['container_name']
            if 'device' in container_tags:
                part_dict['device'] = container_tags['device']
        elif part[-2].startswith('prometheus_'):
            name = part[-2][len('prometheus_'):]
            try:
                prometheus_name = self.get_prometheus_exporter_name(name, part)
            except KeyError:
                logging.debug(
                    'Unknown prometheus exporter.'
                    ' Is it configured in Bleemeo agent ?'
                    ' And telegraf restarted after last telegraf'
                    ' config update ?'
                )
                return {}
            exporter_config = (
                self.core.config['metric.prometheus'][prometheus_name]
            )

            # tags will contains:
            # * url
            # * all prometheus label
            # Remove host and url, keep other in item
            url_mangled = telegraf_replace(exporter_config['url'])
            item_part = []
            for i in part[2:-2]:
                if i != url_mangled and i:
                    item_part.append(i)
            if item_part:
                part_dict['item'] = '-'.join(item_part)
        elif part[-2] == 'phpfpm':
            part_dict['instance'] = part[2]

        return part_dict

    def close(self):
        self._check_computed_metrics()

    def emit_metric(self, name, timestamp, value):
        # pylint: disable=too-many-statements
        # pylint: disable=too-many-branches
        # pylint: disable=too-many-return-statements
        # pylint: disable=too-many-locals
        """ Rename a metric and pass it to core

            If the metric is used to compute a derrived metric, add it to
            computed_metrics_pending.

            Nothing is emitted if metric is unknown
            More that one metrics could be emitted to core
        """
        self.graphite_server.data_last_seen_at = bleemeo_agent.util.get_clock()

        if timestamp - self.last_timestamp > 1:
            self._check_computed_metrics()
        self.last_timestamp = timestamp

        labels = {}
        service = None
        instance = ''
        container_name = ''
        derive = False
        no_emit = False

        if ';' not in name:
            # Compatibility with older version Telegraf/Telegraf config which
            # don't include graphite_tag_support = true
            part = self._telegraf_compatibility(name)
            if not part:
                return
        else:
            # name looks like
            # telegraf.plugin.metric;label=value;label2=value2
            # telegraf.HOSTNAME.(ITEM_INFO)*.PLUGIN.METRIC
            # example:
            # telegraf.disk.total;device=mapper-vg0-home;fstype=ext4;host=[...]
            # telegraf.mem.used;host=xps-pierref
            # telegraf.cpu.usage_steal;cpu=cpu-total;host=xps-pierref
            tmp = name.split(';')
            names = tmp[0].split('.')
            if len(names) != 3:
                return
            part = {
                'telegraf_plugin': names[1],
                'metric_name': names[2],
            }
            for label in tmp[1:]:
                if '=' not in label:
                    return
                label = label.split('=', 1)
                part[label[0]] = label[1]

        if part['telegraf_plugin'] == 'cpu':
            if part['cpu'] != 'cpu-total':
                return

            name = part['metric_name'].replace('usage_', 'cpu_')
            if name == 'cpu_irq':
                name = 'cpu_interrupt'
            elif name == 'cpu_iowait':
                name = 'cpu_wait'

            if name == 'cpu_idle':
                self.core.emit_metric(
                    bleemeo_agent.type.DEFAULT_METRICPOINT._replace(
                        label='cpu_used',
                        time=timestamp,
                        value=100 - value,
                    )
                )
            if name in ('cpu_used', 'cpu_user', 'cpu_system'):
                self.computed_metrics_pending.add(
                    ('cpu_other', '', '', timestamp)
                )
        elif part['telegraf_plugin'] == 'win_cpu':
            if part['instance'] != '_Total':
                return

            name = part['metric_name']
            if name == 'Percent_Idle_Time':
                name = 'cpu_idle'
            elif name == 'Percent_Interrupt_Time':
                name = 'cpu_interrupt'
            elif name == 'Percent_User_Time':
                name = 'cpu_user'
            elif name == 'Percent_Privileged_Time':
                name = 'cpu_system'
            elif name == 'Percent_DPC_Time':
                name = 'cpu_softirq'
            else:
                return

            if name == 'cpu_idle':
                self.core.emit_metric(
                    bleemeo_agent.type.DEFAULT_METRICPOINT._replace(
                        label='cpu_used',
                        time=timestamp,
                        value=100 - value,
                    )
                )
                self.computed_metrics_pending.add(
                    ('system_load1', '', '', timestamp)
                )
            if name in ('cpu_used', 'cpu_user', 'cpu_system'):
                self.computed_metrics_pending.add(
                    ('cpu_other', '', '', timestamp)
                )
        elif part['telegraf_plugin'] == 'disk':
            # Ignore fstype=rootfs. mountpoint for / is duplicated (at least on
            # old Linux - like wheezy). One time as fstype=rootfs and one time
            # with correct fstype.
            if part['fstype'] == 'rootfs':
                return
            labels['fstype'] = part['fstype']
            path = part['path'].replace('-', '/')
            path = self.graphite_server.disk_path_rename(path)
            if path is None:
                return
            labels['item'] = path

            name = 'disk_' + part['metric_name']
            if name == 'disk_used_percent':
                name = 'disk_used_perc'
        elif part['telegraf_plugin'] == 'win_disk':
            labels['item'] = part['instance']
            name = part['metric_name']
            if labels['item'] == '_Total':
                return

            # For Windows, assimilate disk (which are also named "C:", "D:"...
            # and (mounted) partition like C:
            if self.graphite_server.ignored_disk(labels['item']):
                return

            if name == 'Percent_Free_Space':
                name = 'disk_used_perc'
                value = 100 - value

                # when disk_total is processed, disk_used is also emitted
                self.computed_metrics_pending.add(
                    ('disk_total', labels['item'], None, timestamp)
                )
            elif name == 'Free_Megabytes':
                name = 'disk_free'
                value = value * 1024 * 1024
                self.computed_metrics_pending.add(
                    ('disk_total', labels['item'], None, timestamp)
                )
            else:
                return
        elif part['telegraf_plugin'] == 'diskio':
            labels['item'] = part['_name']
            name = part['metric_name']
            if not name.startswith('io_'):
                name = 'io_' + name
            if self.graphite_server.ignored_disk(labels['item']):
                return
            if name == 'io_weighted_io_time':
                return

            if name == 'io_iops_in_progress':
                name = 'io_in_progress'
            else:
                value = self.get_derivate(
                    name, labels['item'], timestamp, value
                )
                if value is None:
                    return

            if name == 'io_time':
                self.core.emit_metric(
                    bleemeo_agent.type.DEFAULT_METRICPOINT._replace(
                        label='io_utilization',
                        labels=labels,
                        time=timestamp,
                        # io_time is a number of ms spent doing IO(per seconds)
                        # utilization is 100% when we spent 1000ms during one
                        # second
                        value=value / 1000. * 100.,
                    )
                )
        elif part['telegraf_plugin'] == 'win_diskio':
            labels['item'] = part['instance']
            name = part['metric_name']
            if labels['item'] == '_Total':
                return

            # Item looks like "0_C:", "1_D:" or "0_C:_D:" (multiple partition
            # on one disk). Remove the number_ from item and take the smaller
            # letter.
            if '_' in labels['item']:
                item_part = labels['item'].split('_')
                number = item_part[0]
                try:
                    int(number)
                    labels['item'] = sorted(item_part[1:])[0]
                except ValueError:
                    pass

            if self.graphite_server.ignored_disk(labels['item']):
                return

            if name == 'Disk_Read_Bytes_persec':
                name = 'io_read_bytes'
            elif name == 'Disk_Write_Bytes_persec':
                name = 'io_write_bytes'
            elif name == 'Current_Disk_Queue_Length':
                name = 'io_in_progress'
            elif name == 'Disk_Reads_persec':
                name = 'io_reads'
            elif name == 'Disk_Writes_persec':
                name = 'io_writes'
            elif name == 'Percent_Idle_Time':
                name = 'io_utilization'
                value = 100 - value
                self.core.emit_metric(
                    bleemeo_agent.type.DEFAULT_METRICPOINT._replace(
                        label='io_time',
                        labels=labels,
                        time=timestamp,
                        # io_time is a number of ms spent doing IO(per seconds)
                        # utilization is 100% when we spent 1000ms during one
                        # second
                        value=value * 1000. / 100.,
                    )
                )
            else:
                return
        elif part['telegraf_plugin'] == 'mem':
            name = 'mem_' + part['metric_name']
            if name in ('mem_used', 'mem_used_percent'):
                # We don't use mem_used of telegraf (which is
                # mem_total - mem_free)
                # We prefere the "collectd one" (which is
                # mem_total - (mem_free + mem_cached + mem_buffered + mem_slab)

                # mem_used will be computed as mem_total - mem_available
                return  # We don't use mem_used of telegraf.
            if name == 'mem_available_percent':
                name = 'mem_available_perc'
            elif name in ('mem_buffered', 'mem_cached', 'mem_free'):
                pass
            elif name in ('mem_total', 'mem_available'):
                self.computed_metrics_pending.add(
                    ('mem_used', '', '', timestamp)
                )
            else:
                return
        elif part['telegraf_plugin'] == 'win_mem':
            name = part['metric_name']
            if name == 'Available_Bytes':
                name = 'mem_available'
                self.core.emit_metric(
                    bleemeo_agent.type.DEFAULT_METRICPOINT._replace(
                        label='mem_available_perc',
                        time=timestamp,
                        value=value * 100. / self.core.total_memory_size,
                    )
                )
                mem_used = self.core.total_memory_size - value
                self.core.emit_metric(
                    bleemeo_agent.type.DEFAULT_METRICPOINT._replace(
                        label='mem_used',
                        time=timestamp,
                        value=mem_used,
                    )
                )
                self.core.emit_metric(
                    bleemeo_agent.type.DEFAULT_METRICPOINT._replace(
                        label='mem_used_perc',
                        time=timestamp,
                        value=mem_used * 100. / self.core.total_memory_size,
                    )
                )
                self.computed_metrics_pending.add(
                    ('mem_free', '', '', timestamp)
                )
            elif name in (
                    'Standby_Cache_Reserve_Bytes',
                    'Standby_Cache_Normal_Priority_Bytes',
                    'Standby_Cache_Core_Bytes'):
                no_emit = True
                self.computed_metrics_pending.add(
                    ('mem_cached', '', '', timestamp)
                )
            else:
                return
        elif part['telegraf_plugin'] == 'net' and part['interface'] != 'all':
            interface = part['interface']
            if self.graphite_server.network_interface_blacklist(interface):
                return
            labels['item'] = interface

            name = 'net_' + part['metric_name']
            if name in ('net_bytes_recv', 'net_bytes_sent'):
                name = name.replace('bytes', 'bits')
                value = value * 8

            derive = True
        elif part['telegraf_plugin'] == 'win_net':
            item = part['instance']
            if self.graphite_server.network_interface_blacklist(item):
                return
            labels['item'] = item
            name = part['metric_name']

            if name == 'Bytes_Sent_persec':
                name = 'net_bits_sent'
                value = value * 8
            elif name == 'Bytes_Received_persec':
                name = 'net_bits_recv'
                value = value * 8
            elif name == 'Packets_Sent_persec':
                name = 'net_packets_sent'
            elif name == 'Packets_Received_persec':
                name = 'net_packets_recv'
            elif name == 'Packets_Received_Discarded':
                derive = True
                name = 'net_drop_in'
            elif name == 'Packets_Outbound_Discarded':
                derive = True
                name = 'net_drop_out'
            elif name == 'Packets_Received_Errors':
                derive = True
                name = 'net_err_in'
            elif name == 'Packets_Outbound_Errors':
                derive = True
                name = 'net_err_out'
            else:
                return
        elif part['telegraf_plugin'] == 'swap':
            if not self.core.last_facts.get('swap_present', False):
                return
            name = 'swap_' + part['metric_name']
            if name.endswith('_percent'):
                name = name.replace('_percent', '_perc')
            if name in ('swap_in', 'swap_out'):
                derive = True
        elif part['telegraf_plugin'] == 'win_swap':
            if not self.core.last_facts.get('swap_present', False):
                return

            name = part['metric_name']
            if name == 'Percent_Usage':
                name = 'swap_used_perc'
                if value == 0:
                    swap_used = 0.0
                else:
                    swap_used = self.core.total_swap_size / (value / 100.)
                self.core.emit_metric(
                    bleemeo_agent.type.DEFAULT_METRICPOINT._replace(
                        label='swap_used',
                        time=timestamp,
                        value=swap_used,
                    )
                )
                self.core.emit_metric(
                    bleemeo_agent.type.DEFAULT_METRICPOINT._replace(
                        label='swap_free',
                        time=timestamp,
                        value=self.core.total_swap_size - swap_used,
                    )
                )
        elif part['telegraf_plugin'] == 'system':
            name = 'system_' + part['metric_name']
            if name == 'system_uptime':
                name = 'uptime'
            elif name == 'system_n_users':
                name = 'users_logged'
            elif name not in ('system_load1', 'system_load5', 'system_load15'):
                return
        elif part['telegraf_plugin'] == 'win_system':
            name = part['metric_name']
            if name == 'System_Up_Time':
                name = 'uptime'
            elif name == 'Processor_Queue_Length':
                no_emit = True
                self.computed_metrics_pending.add(
                    ('system_load1', '', '', timestamp)
                )
            else:
                return
        elif part['telegraf_plugin'] == 'processes':
            if part['metric_name'] in ['blocked', 'running', 'sleeping',
                                       'stopped', 'zombies', 'paging']:
                name = 'process_status_%s' % part['metric_name']
            elif part['metric_name'] == 'total':
                name = 'process_total'
            else:
                return
        elif part['telegraf_plugin'] == 'apache':
            service = 'apache'
            server_address = part['server'].replace('_', '.')
            server_port = int(part['port'])
            try:
                instance = self._get_service_instance(
                    service, server_address, server_port
                )
            except KeyError:
                return

            name = 'apache_' + part['metric_name']
            if name == 'apache_IdleWorkers':
                name = 'apache_idle_workers'
            elif name == 'apache_TotalAccesses':
                name = 'apache_requests'
                derive = True
            elif name == 'apache_TotalkBytes':
                name = 'apache_bytes'
                derive = True
            elif name == 'apache_ConnsTotal':
                name = 'apache_connections'
            elif name == 'apache_Uptime':
                name = 'apache_uptime'
            elif 'scboard' in name:
                name = name.replace('scboard', 'scoreboard')
            else:
                return
            if name.startswith('apache_scoreboard_'):
                self.computed_metrics_pending.add(
                    ('apache_max_workers', instance, instance, timestamp)
                )
        elif part['telegraf_plugin'] == 'haproxy':
            service = 'haproxy'
            proxy_name = part['proxy']
            if part['sv'] not in ('BACKEND', 'FRONTEND'):
                return
            hostport = part['server'].replace('_', '.')
            try:
                instance = self._get_haproxy_instance(hostport)
            except KeyError:
                return

            if (part['metric_name'] in ('stot', 'bin', 'bout', 'dreq', 'dresp',
                                        'ereq', 'econ', 'eresp', 'req_tot')):
                derive = True
                name = 'haproxy_' + part['metric_name']
            elif (part['metric_name'] in ('qcur', 'scur', 'qtime', 'ctime',
                                          'rtime', 'ttime')):
                name = 'haproxy_' + part['metric_name']
            elif part['metric_name'] == 'active_servers':
                name = 'haproxy_act'
            else:
                return

            if not instance:
                labels['item'] = proxy_name
            else:
                labels['item'] = instance + '_' + proxy_name
        elif part['telegraf_plugin'] == 'memcached':
            service = 'memcached'
            (server_address, server_port) = part['server'].split(':')
            server_address = server_address.replace('_', '.')
            server_port = int(server_port)
            try:
                instance = self._get_service_instance(
                    service, server_address, server_port
                )
            except KeyError:
                return

            name = 'memcached_' + part['metric_name']
            if '_cmd_' in name:
                name = name.replace('_cmd_', '_command_')
                derive = True
            elif name == 'memcached_curr_connections':
                name = 'memcached_connections_current'
            elif name == 'memcached_curr_items':
                name = 'memcached_items_current'
            elif name == 'memcached_bytes_read':
                name = 'memcached_octets_rx'
                derive = True
            elif name == 'memcached_bytes_written':
                name = 'memcached_octets_tx'
                derive = True
            elif name == 'memcached_evictions':
                name = 'memcached_ops_evictions'
                derive = True
            elif name == 'memcached_threads':
                name = 'memcached_ps_count_threads'
            elif name in ('memcached_get_misses', 'memcached_get_hits'):
                name = name.replace('_get_', '_ops_')
                derive = True
            elif name.endswith('_misses') or name.endswith('_hits'):
                name = name.replace('memcached_', 'memcached_ops_')
                derive = True
            elif name != 'memcached_uptime':
                return
        elif part['telegraf_plugin'] in ('mysql', 'mysql_innodb'):
            service = 'mysql'
            (server_address, server_port) = part['server'].split(':')
            server_address = server_address.replace('_', '.')
            server_port = int(server_port)
            try:
                instance = self._get_service_instance(
                    service, server_address, server_port
                )
            except KeyError:
                return

            name = part['telegraf_plugin'] + '_' + part['metric_name']
            derive = True
            if name.startswith('mysql_qcache_'):
                name = name.replace('qcache', 'cache_result_qcache')
                if name == 'mysql_cache_result_qcache_lowmem_prunes':
                    name = 'mysql_cache_result_qcache_prunes'
                elif name == 'mysql_cache_result_qcache_queries_in_cache':
                    name = 'mysql_cache_size_qcache'
                    derive = False
                elif name == 'mysql_cache_result_qcache_total_blocks':
                    name = 'mysql_cache_blocksize_qcache'
                    derive = False
                elif name in ('mysql_cache_result_qcache_free_blocks',
                              'mysql_cache_result_qcache_free_memory'):
                    name = name.replace(
                        'mysql_cache_result_qcache_', 'mysql_cache_')
                    derive = False
            elif name.startswith('mysql_table_locks_'):
                name = name.replace('mysql_table_locks_', 'mysql_locks_')
            elif name == 'mysql_bytes_received':
                name = 'mysql_octets_rx'
            elif name == 'mysql_bytes_sent':
                name = 'mysql_octets_tx'
            elif name == 'mysql_threads_created':
                name = 'mysql_total_threads_created'
            elif name.startswith('mysql_threads_'):
                # Other mysql_threads_* name are fine. Accept them unchanged
                derive = False
            elif name.startswith('mysql_commands_'):
                # mysql_commands_* name are fine. Accept them unchanged
                pass
            elif name.startswith('mysql_handler_'):
                # mysql_handler_* name are fine. Accept them unchanged
                pass
            elif name in ('mysql_queries', 'mysql_slow_queries'):
                pass
            elif name == 'mysql_innodb_row_lock_current_waits':
                derive = False
                name = 'mysql_innodb_locked_transaction'
            elif name == 'mysql_innodb_trx_rseg_history_len':
                derive = False
                name = 'mysql_innodb_history_list_len'
            else:
                return
        elif part['telegraf_plugin'] == 'nginx':
            service = 'nginx'
            server_address = part['server'].replace('_', '.')
            server_port = int(part['port'])
            try:
                instance = self._get_service_instance(
                    service, server_address, server_port
                )
            except KeyError:
                return

            name = 'nginx_connections_' + part['metric_name']
            if name == 'nginx_connections_requests':
                name = 'nginx_requests'
                derive = True
            elif name == 'nginx_connections_accepts':
                name = 'nginx_connections_accepted'
                derive = True
            elif name == 'nginx_connections_handled':
                derive = True
        elif part['telegraf_plugin'] == 'postgresql':
            service = 'postgresql'
            dbname = part['db']

            if dbname in ('template0', 'template1'):
                return

            connect_string = part['server']
            # connect string look like:
            # "host=172_17_0_4_port=5432_user=bleemeo_user_dbname=postgres"
            match = re.match(
                r'^host=(.*)_port=(.*)_user=.*$',
                connect_string,
            )
            if not match:
                return

            server_address = match.group(1).replace('_', '.')
            server_port = int(match.group(2))
            try:
                instance = self._get_service_instance(
                    service, server_address, server_port
                )
            except KeyError:
                return

            derive = True
            if part['metric_name'] == 'xact_commit':
                name = 'postgresql_commit'
            elif part['metric_name'] == 'xact_rollback':
                name = 'postgresql_rollback'
            elif (part['metric_name'] in ('blks_read', 'blks_hit',
                                          'tup_returned', 'tup_fetched',
                                          'tup_inserted', 'tup_updated',
                                          'tup_deleted', 'temp_files',
                                          'temp_bytes', 'blk_read_time',
                                          'blk_write_time')):
                name = 'postgresql_' + part['metric_name']
            else:
                return

            if not instance:
                labels['item'] = dbname
            else:
                labels['item'] = instance + '_' + dbname
                labels['dbname'] = dbname
        elif part['telegraf_plugin'] == 'redis':
            service = 'redis'
            server_address = part['server'].replace('_', '.')
            server_port = int(part['port'])
            try:
                instance = self._get_service_instance(
                    service, server_address, server_port
                )
            except KeyError:
                return

            name = 'redis_' + part['metric_name']

            if name == 'redis_clients':
                name = 'redis_current_connections_clients'
            elif name == 'redis_connected_slaves':
                name = 'redis_current_connections_slaves'
            elif name.startswith('redis_used_memory'):
                name = name.replace('redis_used_memory', 'redis_memory')
            elif name == 'redis_total_connections_received':
                name = 'redis_total_connections'
                derive = True
            elif name == 'redis_total_commands_processed':
                name = 'redis_total_operations'
                derive = True
            elif name == 'redis_rdb_changes_since_last_save':
                name = 'redis_volatile_changes'
            elif name in ('redis_evicted_keys', 'redis_keyspace_hits',
                          'redis_keyspace_misses', 'redis_expired_keys'):
                derive = True
            elif name in ('redis_uptime', 'redis_pubsub_patterns',
                          'redis_pubsub_channels', 'redis_keyspace_hitrate'):
                pass
            else:
                return
        elif part['telegraf_plugin'] == 'zookeeper':
            service = 'zookeeper'

            # Telegraf 1.0.0 added "state" in tag. Which change position of
            # server_address and server_port.

            # Telegraf <1.0.0, output was:
            # telegraf.$HOSTNAME.$PORT.$SERVER.zookeeper.$METRIC
            # Telegraf 1.0.0+, output is:
            # telegraf.$HOSTNAME.$PORT.$SERVER.$STATE.zookeeper.$METRIC
            server_address = part['server'].replace('_', '.')
            server_port = int(part['port'])
            try:
                instance = self._get_service_instance(
                    service, server_address, server_port
                )
            except KeyError:
                return

            name = 'zookeeper_' + part['metric_name']
            if name.startswith('zookeeper_packets_'):
                derive = True
            elif name in ('zookeeper_ephemerals_count',
                          'zookeeper_watch_count', 'zookeeper_znode_count'):
                pass
            elif name == 'zookeeper_num_alive_connections':
                name = 'zookeeper_connections'
            else:
                return
        elif part['telegraf_plugin'] == 'mongodb':
            service = 'mongodb'
            (server_address, server_port) = part['hostname'].split(':')
            server_address = server_address.replace('_', '.')
            server_port = int(server_port)
            try:
                instance = self._get_service_instance(
                    service, server_address, server_port
                )
            except KeyError:
                return

            name = 'mongodb_' + part['metric_name']
            if name in ('mongodb_open_connections', 'mongodb_queued_reads',
                        'mongodb_queued_writes', 'mongodb_active_reads',
                        'mongodb_active_writes'):
                pass
            elif name == 'mongodb_queries_per_sec':
                name = 'mongodb_queries'
            elif name in ('mongodb_net_out_bytes', 'mongodb_net_in_bytes'):
                derive = True
            else:
                return
        elif part['telegraf_plugin'].startswith('elasticsearch_'):
            service = 'elasticsearch'
            # It can't rely only on part['node_host'], because this is the
            # host as think by ES (usually the "public" IP of the node). But
            # Agent use "127.0.0.1" for localhost.
            # server_address = part['node_host'].replace('_', '.')

            node_id = part['node_id']
            try:
                instance = self._get_elasticsearch_instance(node_id)
            except KeyError:
                return

            name = None
            if part['telegraf_plugin'] == 'elasticsearch_indices':
                if part['metric_name'] == 'docs_count':
                    name = 'elasticsearch_docs_count'
                elif part['metric_name'] == 'store_size_in_bytes':
                    name = 'elasticsearch_size'
                elif part['metric_name'] == 'search_query_total':
                    name = 'elasticsearch_search'
                    derive = True
                    self.computed_metrics_pending.add(
                        (
                            'elasticsearch_search_time',
                            instance,
                            instance,
                            timestamp
                        )
                    )
                elif part['metric_name'] == 'search_query_time_in_millis':
                    name = 'elasticsearch_search_time_total'
                    derive = True
                    no_emit = True
                    self.computed_metrics_pending.add(
                        (
                            'elasticsearch_search_time',
                            instance,
                            instance,
                            timestamp
                        )
                    )
            elif part['telegraf_plugin'] == 'elasticsearch_jvm':
                if part['metric_name'] == 'mem_heap_used_in_bytes':
                    name = 'elasticsearch_jvm_heap_used'
                elif part['metric_name'] == 'mem_non_heap_used_in_bytes':
                    name = 'elasticsearch_jvm_non_heap_used'
                elif part['metric_name'] == (
                        'gc_collectors_old_collection_count'):
                    name = 'elasticsearch_jvm_gc_old'
                    no_emit = True
                    derive = True
                    self.computed_metrics_pending.add(
                        (
                            'elasticsearch_jvm_gc',
                            instance,
                            instance,
                            timestamp
                        )
                    )
                elif part['metric_name'] == (
                        'gc_collectors_young_collection_count'):
                    name = 'elasticsearch_jvm_gc_young'
                    no_emit = True
                    derive = True
                    self.computed_metrics_pending.add(
                        (
                            'elasticsearch_jvm_gc',
                            instance,
                            instance,
                            timestamp
                        )
                    )
                elif part['metric_name'] == (
                        'gc_collectors_old_collection_time_in_millis'):
                    name = 'elasticsearch_jvm_gc_time_old'
                    no_emit = True
                    derive = True
                    self.computed_metrics_pending.add(
                        (
                            'elasticsearch_jvm_gc_time',
                            instance,
                            instance,
                            timestamp
                        )
                    )
                elif part['metric_name'] == (
                        'gc_collectors_young_collection_time_in_millis'):
                    name = 'elasticsearch_jvm_gc_time_young'
                    no_emit = True
                    derive = True
                    self.computed_metrics_pending.add(
                        (
                            'elasticsearch_jvm_gc_time',
                            instance,
                            instance,
                            timestamp
                        )
                    )
        elif part['telegraf_plugin'] == 'rabbitmq_overview':
            service = 'rabbitmq'

            tmp = part['url']
            if not tmp.startswith('http:--'):
                return  # unknown format
            tmp = tmp[len('http:--'):]
            (server_address, server_port) = tmp.split(':')
            server_address = server_address.replace('_', '.')
            server_port = int(server_port)
            try:
                instance = self._get_service_instance(
                    service, server_address, server_port
                )
            except KeyError:
                return

            if part['metric_name'] == 'messages':
                name = 'rabbitmq_messages_count'
            elif part['metric_name'] == 'consumers':
                name = 'rabbitmq_consumers'
            elif part['metric_name'] == 'connections':
                name = 'rabbitmq_connections'
            elif part['metric_name'] == 'queues':
                name = 'rabbitmq_queues'
            elif part['metric_name'] == 'messages_published':
                derive = True
                name = 'rabbitmq_messages_published'
            elif part['metric_name'] == 'messages_delivered':
                derive = True
                name = 'rabbitmq_messages_delivered'
            elif part['metric_name'] == 'messages_acked':
                derive = True
                name = 'rabbitmq_messages_acked'
            elif part['metric_name'] == 'messages_unacked':
                name = 'rabbitmq_messages_unacked_count'
            else:
                return
        elif part['telegraf_plugin'] == 'docker':
            if part['metric_name'] == 'n_containers':
                name = 'docker_containers'
            else:
                return
        elif part['telegraf_plugin'] == 'docker_container_cpu':
            if part['metric_name'] == 'usage_total':
                name = 'docker_container_cpu_used'
                # Docker sends time in nanosecond. Convert it to seconds
                value = value / 1000000000

                # And return a percentage
                derive = True
                value = value * 100
            else:
                return
            labels['item'] = part['container_name']
            if labels['item'] not in self.core.docker_containers_by_name:
                return

            if part.get('cpu') != 'cpu-total':
                return
        elif part['telegraf_plugin'] == 'docker_container_mem':
            if part['metric_name'] == 'usage_percent':
                name = 'docker_container_mem_used_perc'
            elif part['metric_name'] == 'usage':
                name = 'docker_container_mem_used'
            else:
                return

            labels['item'] = part['container_name']
            if labels['item'] not in self.core.docker_containers_by_name:
                return
        elif part['telegraf_plugin'] == 'docker_container_net':
            if part['metric_name'] == 'rx_bytes':
                name = 'docker_container_net_bits_recv'
                value = value * 8  # Convert bytes => bits
                derive = True
            elif part['metric_name'] == 'tx_bytes':
                name = 'docker_container_net_bits_sent'
                value = value * 8  # Convert bytes => bits
                derive = True
            else:
                return

            labels['item'] = part['container_name']
            if labels['item'] not in self.core.docker_containers_by_name:
                return

            if part.get("network") != 'total':
                return
        elif part['telegraf_plugin'] == 'docker_container_blkio':
            if part['metric_name'] == 'io_service_bytes_recursive_read':
                name = 'docker_container_io_read_bytes'
                derive = True
            elif part['metric_name'] == 'io_service_bytes_recursive_write':
                name = 'docker_container_io_write_bytes'
                derive = True
            else:
                return

            labels['item'] = part['container_name']
            if labels['item'] not in self.core.docker_containers_by_name:
                return

            if part.get("device") != 'total':
                return
        elif part['telegraf_plugin'].startswith('prometheus_'):
            name = part['telegraf_plugin'][len('prometheus_'):]

            item_part = []
            for (k, v) in sorted(part.items()):  # pylint: disable=invalid-name
                if k in ['telegraf_plugin', 'metric_name', 'url', 'host']:
                    continue
                if not v:
                    continue
                item_part.append(v)
                labels[k] = v
            if item_part:
                labels['item'] = '-'.join(item_part)
            if part['metric_name'] == 'counter':
                if name.endswith('_total'):
                    # Agent don't send a total, but a derivate.
                    name = name[:-len('_total')]
                derive = True
            elif part['metric_name'] == 'gauge':
                pass
            elif part['metric_name'] == 'sum':
                derive = True
                no_emit = True
                self.computed_metrics_pending.add(
                    (
                        'prometheus_' + name,
                        labels.get('item', ''),
                        None,
                        timestamp
                    )
                )
                name = name + '_sum'
            elif part['metric_name'] == 'count':
                derive = True
                no_emit = True
                self.computed_metrics_pending.add(
                    (
                        'prometheus_' + name,
                        labels.get('item', ''),
                        None,
                        timestamp
                    )
                )
                name = name + '_count'
            elif part['metric_name'] in ('5', '0', '1'):
                # This is used by quantile and histogram. (0 is in
                # fact 0.1, 0.25...)
                # Agent don't process them on use only sum and count.
                return
            else:
                logging.debug(
                    'Unknown Prometheus metric: %s_%s',
                    name,
                    part['metric_name'],
                )
                return
        elif part['telegraf_plugin'] == 'phpfpm':
            service = 'phpfpm'
            if ('instance' in part
                    and ('phpfpm', part['instance']) in self.core.services):
                instance = part['instance']

            name = 'phpfpm_' + part['metric_name']

            if name in {'phpfpm_accepted_conn', 'phpfpm_slow_requests'}:
                derive = True
        elif (part.get('metric_type', '') == 'counter'
              and self.core.config['telegraf.statsd.enabled']):
            # statsd counter
            derive = True
            name = 'statsd_' + part['telegraf_plugin']
        elif (part.get('metric_type', '') == 'gauge'
              and self.core.config['telegraf.statsd.enabled']):
            # statsd gauge
            name = 'statsd_' + part['telegraf_plugin']
        elif (part.get('metric_type', '') == 'timing'
              and self.core.config['telegraf.statsd.enabled']):
            # statsd timing
            name = (
                'statsd_' + part['telegraf_plugin'] + '_' + part['metric_name']
            )
            if part['metric_name'] == 'count':
                # count for timing are number of item per 10 seconds.
                # We want a count per second.
                value = value / 10
        else:
            return

        if name is None:
            return

        if 'item' not in labels and service and instance:
            labels['item'] = instance

        if derive:
            value = self.get_derivate(
                name, labels.get('item', ''), timestamp, value,
            )
            if value is None:
                return

        if service is None:
            service = ''
            instance = ''

        if container_name is None:
            container_name = ''
        self.core.emit_metric(
            bleemeo_agent.type.DEFAULT_METRICPOINT._replace(
                label=name,
                labels=labels,
                time=timestamp,
                value=value,
                service_label=service,
                service_instance=instance,
                container_name=container_name,
            ),
            no_emit=no_emit
        )

    def packet_finish(self):
        """ Called when graphite_client finished processing one TCP packet
        """
        self._check_computed_metrics()

    def _check_computed_metrics(self):
        """ Some metric are computed from other one. For example CPU stats
            are aggregated over all CPUs.

            When any cpu state arrive, we flag the aggregate value as "pending"
            and this function check if stats for all CPU core are fresh enough
            to compute the aggregate.

            This function use computed_metrics_pending, which old a list
            of (metric_name, item, timestamp).
            Item is something like "sda", "sdb" or "eth0", "eth1".
        """
        processed = set()
        new_item = set()
        for entry in self.computed_metrics_pending:
            (name, item, instance, timestamp) = entry
            try:
                self._compute_metric(name, item, instance, timestamp, new_item)
                processed.add(entry)
            except ComputationFail:
                logging.debug(
                    'Failed to compute metric %s at time %s',
                    name, timestamp)
                # we will never be able to recompute it.
                # mark it as done and continue :/
                processed.add(entry)
            except MissingMetric:
                # Some metric are missing to do computing. Wait a bit by
                # keeping this entry in computed_metrics_pending
                pass

        self.computed_metrics_pending.difference_update(processed)
        new_item.difference_update(processed)
        if new_item:
            self.computed_metrics_pending.update(new_item)
            self._check_computed_metrics()

    def _compute_metric(self, name, item, instance, timestamp, new_item):
        # pylint: disable=too-many-statements
        # pylint: disable=too-many-branches
        # pylint: disable=too-many-locals
        # pylint: disable=too-many-arguments
        def get_metric(measurements, searched_item):
            """ Helper that do common task when retriving metrics:

                * check that metric exists and is not too old
                  (or Raise MissingMetric)
                * If the last metric is more recent that the one we want
                  to compute, raise ComputationFail. We will never be
                  able to compute the requested value.
            """
            metric_point = self.core.get_last_metric(
                measurements, searched_item
            )
            if metric_point is None or metric_point.time < timestamp:
                raise MissingMetric()
            if metric_point.time > timestamp:
                raise ComputationFail()
            return metric_point.value

        service = None

        if name == 'disk_total' and os.name == 'nt':
            used_perc = get_metric('disk_used_perc', item)
            free = get_metric('disk_free', item)
            free_perc = 100 - used_perc
            disk_total = free / (free_perc / 100.0)
            disk_used = disk_total * (used_perc / 100.0)
            value = disk_total
            self.core.emit_metric(
                bleemeo_agent.type.DEFAULT_METRICPOINT._replace(
                    label='disk_used',
                    labels={
                        'item': item,
                    },
                    time=timestamp,
                    value=disk_used,
                )
            )
        elif name == 'cpu_other':
            value = get_metric('cpu_used', '')
            value -= get_metric('cpu_user', '')
            value -= get_metric('cpu_system', '')
        elif name == 'mem_free' and os.name == 'nt':
            used = get_metric('mem_used', item)
            cached = get_metric('mem_cached', item)
            value = self.core.total_memory_size - used - cached
        elif name == 'mem_cached' and os.name == 'nt':
            value = 0
            for sub_type in (
                    'Standby_Cache_Reserve_Bytes',
                    'Standby_Cache_Normal_Priority_Bytes',
                    'Standby_Cache_Core_Bytes'):
                value += get_metric(sub_type, item)
            new_item.add(
                ('mem_free', '', '', timestamp)
            )
        elif name == 'mem_used':
            total = get_metric('mem_total', '')
            value = total - get_metric('mem_available', '')
            self.core.emit_metric(
                bleemeo_agent.type.DEFAULT_METRICPOINT._replace(
                    label='mem_used_perc',
                    time=timestamp,
                    value=value / total * 100,
                )
            )
        elif name == 'system_load1':
            # Unix load represent the number of running and runnable tasks
            # which include task waiting for disk IO.

            # To re-create the value on Windows:
            # Number of running task will be number of CPU core * CPU usage
            # Number of runnable tasks will be "Processor Queue Length", but
            # this probably does not include task waiting for disk IO.

            cpu_used = get_metric('cpu_used', '')
            runq = get_metric('Processor_Queue_Length', '')
            core_count = psutil.cpu_count()
            if core_count is None:
                core_count = 1
            value = core_count * (cpu_used / 100.) + runq
        elif name == 'elasticsearch_search_time':
            service = 'elasticsearch'
            total = get_metric('elasticsearch_search_time_total', item)
            count = get_metric('elasticsearch_search', item)
            if count == 0:
                # If not query during the period, the average time
                # has not meaning. Don't emit it at all.
                return
            value = total / count
        elif name == 'elasticsearch_jvm_gc':
            service = 'elasticsearch'
            gc_old = get_metric('elasticsearch_jvm_gc_old', item)
            gc_young = get_metric('elasticsearch_jvm_gc_young', item)
            value = gc_old + gc_young
        elif name == 'elasticsearch_jvm_gc_time':
            service = 'elasticsearch'
            gc_old = get_metric('elasticsearch_jvm_gc_time_old', item)
            gc_young = get_metric('elasticsearch_jvm_gc_time_young', item)
            value = gc_old + gc_young

            labels = {}
            if not item:
                item = ''
            else:
                labels['item'] = item
            self.core.emit_metric(
                bleemeo_agent.type.DEFAULT_METRICPOINT._replace(
                    label='elasticsearch_jvm_gc_utilization',
                    labels=labels,
                    time=timestamp,
                    value=value / 10.,  # convert ms/s in %
                    service_label=service,
                    service_instance=instance,
                )
            )
        elif name == 'apache_busy_workers':
            service = 'apache'
            max_worker = get_metric('apache_max_workers', item)
            idle_worker = get_metric('apache_scoreboard_waiting', item)
            open_worker = get_metric('apache_scoreboard_open', item)
            value = max_worker - idle_worker - open_worker
            labels = {}
            if not item:
                item = ''
            else:
                labels['item'] = item
            self.core.emit_metric(
                bleemeo_agent.type.DEFAULT_METRICPOINT._replace(
                    label='apache_busy_workers_perc',
                    labels=labels,
                    time=timestamp,
                    value=100 * value / max_worker,
                    service_label=service,
                    service_instance=instance,
                )
            )
        elif name == 'apache_max_workers':
            service = 'apache'
            value = 0
            for sub_type in (
                    'apache_scoreboard_waiting',
                    'apache_scoreboard_starting',
                    'apache_scoreboard_reading',
                    'apache_scoreboard_sending',
                    'apache_scoreboard_keepalive',
                    'apache_scoreboard_dnslookup',
                    'apache_scoreboard_closing',
                    'apache_scoreboard_logging',
                    'apache_scoreboard_finishing',
                    'apache_scoreboard_idle_cleanup',
                    'apache_scoreboard_open'):
                value += get_metric(sub_type, item)
            new_item.add(
                ('apache_busy_workers', item, instance, timestamp)
            )
        elif name.startswith('prometheus_'):
            name = name[len('prometheus_'):]
            count = get_metric(name + '_count', item)
            total = get_metric(name + '_sum', item)
            if count == 0:
                # If no item during the period, the average has
                # no meaning. Don't emit the metric at all.
                return
            value = total / count
        else:
            logging.debug('Unknown computed metric %s', name)
            return
        labels = {}
        if not item:
            item = ''
        else:
            labels['item'] = item
        if service is None:
            service = ''
            instance = ''
        self.core.emit_metric(
            bleemeo_agent.type.DEFAULT_METRICPOINT._replace(
                label=name,
                labels=labels,
                time=timestamp,
                value=value,
                service_label=service,
                service_instance=instance,
            )
        )


def _get_telegraf_config(core):
    # pylint: disable=too-many-statements
    # pylint: disable=too-many-branches
    telegraf_config = BASE_TELEGRAF_CONFIG % {
        'interval': core.metric_resolution,
    }

    if core.config['telegraf.statsd.enabled']:
        telegraf_config += STATSD_TELEGRAF_CONFIG % {
            'address': core.config['telegraf.statsd.address'],
            'port': core.config['telegraf.statsd.port'],
        }

    if core.docker_client is not None:
        docker_metrics_enabled = core.config['telegraf.docker_metrics_enabled']
        if (docker_metrics_enabled
                or (
                    docker_metrics_enabled is None
                    and telegraf_version_gte(core, '1.0.0')
                )):
            telegraf_config += DOCKER_TELEGRAF_CONFIG

    for (key, service_info) in sorted(core.services.items()):
        if not service_info.get('active', True):
            continue
        if service_info.get('ignore_metrics', False):
            continue
        (service_name, instance) = key

        service_info = core.services[key].copy()
        service_info['instance'] = instance

        if not service_info.get('container_running', True):
            continue

        if (service_name == 'haproxy'
                and service_info.get('stats_url') is not None):
            telegraf_config += HAPROXY_TELEGRAF_CONFIG % service_info
        if (service_name == 'phpfpm'
                and (
                    service_info.get('stats_url') is not None
                    or service_info.get('port') is not None
                    or service_info.get('netstat_ports'))):
            copy_info = service_info.copy()
            port = service_info.get('port')
            for port_proto in service_info.get('netstat_ports', {}):
                if port is not None:
                    break
                if port_proto.endswith('/tcp'):
                    port = port_proto.split('/')[0]
            if ('stats_url' not in copy_info
                    and service_info.get('address') is None):
                continue

            if port is None and 'stats_url' not in copy_info:
                continue

            copy_info.setdefault(
                'stats_url',
                'fcgi://%s:%s/status' % (
                    service_info.get('address'),
                    port,
                )
            )
            if instance:
                copy_info['tags'] = (
                    '[inputs.phpfpm.tags]\n        instance = "%s"' %
                    instance
                )
            else:
                copy_info['tags'] = ""
            telegraf_config += PHPFPM_TELEGRAF_CONFIG % copy_info

        # All next services require an address.
        if service_info.get('address') is None:
            continue

        if service_name == 'rabbitmq':
            service_info.setdefault('username', 'guest')
            service_info.setdefault('password', 'guest')
            service_info.setdefault('mgmt_port', 15672)
            telegraf_config += RABBITMQ_TELEGRAF_CONFIG % service_info

        # All next services require a port.
        if service_info.get('port') is None:
            continue

        if service_name == 'apache':
            if service_info.get('port') == 80:
                status_url = 'http://%(address)s/server-status?auto'
            else:
                status_url = 'http://%(address)s:%(port)s/server-status?auto'
            service_info = service_info.copy()
            service_info.setdefault('status_url', status_url % service_info)
            telegraf_config += APACHE_TELEGRAF_CONFIG % service_info
            if telegraf_version_gte(core, '1.2.0'):
                telegraf_config += APACHE_TELEGRAF_CONFIG_1_2
        if service_name == 'elasticsearch':
            telegraf_config += ELASTICSEARCH_TELEGRAF_CONFIG % service_info
        if service_name == 'memcached':
            telegraf_config += MEMCACHED_TELEGRAF_CONFIG % service_info
        if (service_name == 'mysql'
                and service_info.get('password') is not None):
            service_info.setdefault('username', 'root')
            telegraf_config += MYSQL_TELEGRAF_CONFIG % service_info
            if telegraf_version_gte(core, '1.3.0'):
                telegraf_config += MYSQL_TELEGRAF_CONFIG_1_3
        if service_name == 'mongodb':
            telegraf_config += MONGODB_TELEGRAF_CONFIG % service_info
        if service_name == 'nginx':
            telegraf_config += NGINX_TELEGRAF_CONFIG % service_info
            if telegraf_version_gte(core, '1.4.0'):
                telegraf_config += NGINX_TELEGRAF_CONFIG_1_4
        if (service_name == 'postgresql'
                and service_info.get('password') is not None):
            service_info.setdefault('username', 'postgres')
            telegraf_config += POSTGRESQL_TELEGRAF_CONFIG % service_info
        if service_name == 'redis':
            telegraf_config += REDIS_TELEGRAF_CONFIG % service_info
        if service_name == 'zookeeper':
            telegraf_config += ZOOKEEPER_CONFIG % service_info

    prometheus_config = core.config['metric.prometheus']
    for name in sorted(prometheus_config):
        exporter_config = prometheus_config[name]
        telegraf_config += PROMETHEUS_TELEGRAF_CONFIG % {
            'url': exporter_config['url'],
            'prefix': name,
        }

    return telegraf_config


def _restart_telegraf(core):
    restart_cmd = core.config['telegraf.restart_command']
    telegraf_container = core.config['telegraf.docker_name']
    if telegraf_container is not None:
        if telegraf_container:
            bleemeo_agent.util.docker_restart(
                core.docker_client, telegraf_container
            )
    else:
        try:
            output = subprocess.check_output(
                shlex.split(restart_cmd),
                stderr=subprocess.STDOUT,
            )
            return_code = 0
        except (subprocess.CalledProcessError, OSError) as exception:
            output = exception.output
            return_code = exception.returncode

        if return_code != 0:
            logging.info(
                'Failed to restart telegraf after reconfiguration: %s',
                output
            )
        else:
            logging.debug(
                'telegraf reconfigured and restarted: %s', output)


def telegraf_version_gte(core, version):
    """ Return True if installed Telegraf version is at least given version

        If unable to compare given version with current version, return
        False (for example fact telegraf_version is absent or any error).
    """
    current_version = core.last_facts.get('telegraf_version')
    if current_version is None:
        return False

    try:
        return compare_version(current_version, version)
    except Exception:  # pylint: disable=broad-except
        return False


def _write_config(core):
    telegraf_config = _get_telegraf_config(core)

    telegraf_config_path = core.config['telegraf.config_file']

    if os.path.exists(telegraf_config_path):
        with open(telegraf_config_path) as config_file:
            current_content = config_file.read()

        if telegraf_config == current_content:
            logging.debug('telegraf already configured')
            return False

    # Don't simply use open. This file must have limited permission
    # since it may contains password
    open_flags = os.O_WRONLY | os.O_CREAT | os.O_TRUNC
    fileno = os.open(telegraf_config_path, open_flags, 0o600)
    with os.fdopen(fileno, 'w') as config_file:
        config_file.write(telegraf_config)
    return True
